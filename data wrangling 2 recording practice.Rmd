---
title: "data-wrangling 2 practice"
author: "Seonyoung Park (sp3804)"
date: "11/1/2020"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)
library(httr)
```

## Scrap a table

I want the first table from [here]http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm]

read in the html

```{r}
url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"
drug_use_html = read_html(url)

```

1. extract the table(s); from the website, I've extracted all the tables
2. I'm gonna focus on the first one
3. get html table
4. cut the first row (the “note” at the bottom of the table appears in every column in the first row.)
5. change it to table

```{r}
table_mar = 
  drug_use_html %>%
  html_nodes(css = "table") %>%
  first() %>%
  html_table %>%
  slice(-1) %>%
  as_tibble()

table_mar
```

## Star Wars Movie Info

I want the data from [here](https://www.imdb.com/list/ls070150896/).

```{r}
url="https://www.imdb.com/list/ls070150896/"

swm_html = read_html(url)

```

Grab elements that I want- using SelectorGadget
1. Extract each vector
2. Make a table using all the vectors. 

```{r}
title_vec = 
  swm_html %>%
  html_nodes(css = ".lister-item-header a") %>%
  html_text()

gross_rev_vec = 
  swm_html %>%
  html_nodes(css = ".text-muted .ghost~ .text-muted+ span") %>%
  html_text()

runtime_vec = 
  swm_html %>%
  html_nodes(css = ".runtime") %>%
  html_text()

swm_df = 
  tibble(
    title = title_vec,
    gross_rev = gross_rev_vec,
    runtime = runtime_vec
  )
```

## Get some water data

1. This is coming from an API; if we can use csv, always use csv first. If not, use Jason, but more work to do. 

2. content("parsed") make a tibble. 

```{r}
nyc_water = 
  GET("https://data.cityofnewyork.us/resource/ia2d-e54m.csv") %>%
  content("parsed")

nyc_water = 
  GET("https://data.cityofnewyork.us/resource/ia2d-e54m.json") %>% 
  content("text") %>%
  jsonlite::fromJSON() %>%
  as_tibble()

```


## BRFSS

Same process, different data

```{r}
brfss_2010 = 
  GET("https://chronicdata.cdc.gov/resource/acme-vg9e.csv") %>%
  content("parsed")

```

By default, the CDC API limits data to the first 1000 rows. Here I’ve increased that by changing an element of the API query. 
I looked around the website describing the API to find the name of the argument, and then used the appropriate syntax for GET.
To get the full data, I could increase this so that I get all the data at once or I could try iterating over chunks of a few thousand rows.

* The "$limit" parameter chooses how many records to return per page, and "$offset" tells the API on what record to start returning data.
* GET("http://google.com/", path = "search", query = list(q = "ham"))

```{r}
brfss_2010 = 
  GET("https://chronicdata.cdc.gov/resource/acme-vg9e.csv", query = list("$limit"=5000)) %>%
  content("parsed")

```


